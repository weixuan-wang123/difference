{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a315a35d-c6d2-41dd-9e93-ce9f9d6e67e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"/bask/homes/f/fksv3157/xngs6460-languages/weixuan/model/llama2-7b-chat\"  \n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer,AutoModelForCausalLM,GenerationConfig\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4c8a3e-9ce9-47a6-b1cf-bd0366be0c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "punc = ['.</s>','.\\n','.',';','!',',','?','\\n','</s>','<pad>']\n",
    "def evalone(ans_res,reference):\n",
    "    ans = ans_res.strip()\n",
    "    for p in punc:\n",
    "        ans = ans.replace(p, \"\")\n",
    "    if ans.lower() == reference.strip().lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee3783c-0c47-45e5-aa4d-4c0b70811d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "def load_xcopa():\n",
    "    test_data = []\n",
    "    with open(f\"/bask/homes/f/fksv3157/xngs6460-languages/weixuan/data/xcopa/test.en.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = json.load(f)\n",
    "    for line in lines:\n",
    "        prompt_question,cor_answer = line[\"input\"],line[\"output\"]\n",
    "        test_data.append([prompt_question,cor_answer])\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da26707a-ed4f-416c-8200-4b0a5d747e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import tqdm\n",
    "def baseline(file,test_data):\n",
    "    EMs = []\n",
    "    for idx in range(len(test_data)):\n",
    "        q,a = test_data[idx][0],test_data[idx][1]   \n",
    "        target_ids = tokenizer(a, return_tensors='pt')['input_ids'].to('cuda')\n",
    "        inp = tokenizer(f'{q} {a}', return_tensors='pt').to('cuda')\n",
    "        outputs = model(**inp)\n",
    "        logits = outputs.logits\n",
    "        ans = torch.argmax(logits, dim=-1)[:, -target_ids.size(1):-1].squeeze()\n",
    "        ans_idss = ans.detach().cpu().numpy().tolist()\n",
    "\n",
    "        textual_ans = tokenizer.decode(ans_idss, skip_special_tokens=True)\n",
    "        EM = evalone(textual_ans,test_data[idx][1])\n",
    "        EMs.append(EM)\n",
    "    EMs = mean(EMs,axis=0)\n",
    "    print(\"baseline\",EMs)\n",
    "    return EMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f3437e-a952-4896-a89d-0fc0e75d6c34",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = load_xcopa()\n",
    "res_base = baseline(file,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07e3a33-ac34-4d87-8016-05504e0454fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2829b94c-17d3-49fb-a600-b5abfa7f1337",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remake (Conda)",
   "language": "python",
   "name": "sys_remake"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
